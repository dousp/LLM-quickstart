{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hugging Face Transformers 微调语言模型-问答任务-Homework\n",
    "\n",
    "微调训练一个支持问答任务的模型。\n",
    "\n",
    "**注意：微调后的模型仍然是通过提取上下文的子串来回答问题的，而不是生成新的文本。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1.准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 公共"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T04:09:47.162333Z",
     "iopub.status.busy": "2024-03-30T04:09:47.161822Z",
     "iopub.status.idle": "2024-03-30T04:09:47.166985Z",
     "shell.execute_reply": "2024-03-30T04:09:47.166219Z",
     "shell.execute_reply.started": "2024-03-30T04:09:47.162297Z"
    },
    "id": "zVvslsfMIrIh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 根据你使用的模型和GPU资源情况，调整以下关键参数\n",
    "squad_v2 = True\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 64\n",
    "\n",
    "# 数据集\n",
    "dataset_dir = \"/mnt/workspace/dataset\"\n",
    "dataset_squad_v2 = f\"{dataset_dir}/rajpurkar/squad_v2\"\n",
    "dataset_squad_v2_root = f\"{dataset_dir}/rajpurkar/squad_v2/squad_v2\"\n",
    "\n",
    "# 模型\n",
    "model_dir = \"/mnt/workspace/models\"\n",
    "model_distilbert_base_uncased = f\"{model_dir}/distilbert/distilbert-base-uncased/\"\n",
    "model_distilbert_base_uncased_output_dir = f\"{model_dir}/distilbert/distilbert-base-uncased-fine-tune-squad\"\n",
    "\n",
    "# 文本序列最大长度\n",
    "max_length = 384\n",
    "# 拆分上下文时，拆分的重叠长度\n",
    "doc_stride = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 加载数据集、编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T04:09:50.693861Z",
     "iopub.status.busy": "2024-03-30T04:09:50.693400Z",
     "iopub.status.idle": "2024-03-30T04:09:54.962337Z",
     "shell.execute_reply": "2024-03-30T04:09:54.961423Z",
     "shell.execute_reply.started": "2024-03-30T04:09:50.693832Z"
    },
    "id": "IreSlFmlIrIm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "\n",
    "# 加载 SQuAD 数据集\n",
    "datasets = load_dataset(dataset_squad_v2)\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_distilbert_base_uncased)\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
    "\n",
    "# 数据填充\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T04:10:04.427290Z",
     "iopub.status.busy": "2024-03-30T04:10:04.426713Z",
     "iopub.status.idle": "2024-03-30T04:10:04.438724Z",
     "shell.execute_reply": "2024-03-30T04:10:04.438029Z",
     "shell.execute_reply.started": "2024-03-30T04:10:04.427254Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "def prepare_train_features(examples):\n",
    "    # 一些问题的左侧可能有很多空白字符，这对我们没有用，而且会导致上下文的截断失败\n",
    "    # （标记化的问题将占用大量空间）。因此，我们删除左侧的空白字符。\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和填充对我们的示例进行标记化，但保留溢出部分，使用步幅（stride）。\n",
    "    # 当上下文很长时，这会导致一个示例可能提供多个特征，其中每个特征的上下文都与前一个特征的上下文有一些重叠。\n",
    "    # truncation，文本截断的方式，它使得始终对context进行截取\n",
    "    # 标记后的数据格式 {'input_ids': [[...]], 'attention_mask': [[...]], 'offset_mapping': [[ ...],[...]],'overflow_to_sample_mapping': [0, 0]}\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # 由于一个示例可能给我们提供多个特征（如果它具有很长的上下文），我们需要一个从特征到其对应示例的映射。这个键就提供了这个映射关系。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # 偏移映射将为我们提供从令牌到原始上下文中的字符位置的映射。这将帮助我们计算开始位置和结束位置。\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # 让我们为这些示例进行标记！\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # 我们将使用 CLS 特殊 token 的索引来标记不可能的答案。\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        # [CLS] 标记的索引位置\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # 获取与该示例对应的序列（以了解上下文和问题是什么）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # 一个示例可以提供多个跨度，这是包含此文本跨度的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # 如果没有给出答案，则将cls_index设置为答案。\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # 答案在文本中的开始和结束字符索引。\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # 当前跨度在文本中的开始令牌索引。\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # 当前跨度在文本中的结束令牌索引。\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # 检测答案是否超出跨度（在这种情况下，该特征的标签将使用CLS索引）。\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # 否则，将token_start_index和token_end_index移到答案的两端。\n",
    "                # 注意：如果答案是最后一个单词（边缘情况），我们可以在最后一个偏移之后继续。\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T04:10:11.001008Z",
     "iopub.status.busy": "2024-03-30T04:10:11.000515Z",
     "iopub.status.idle": "2024-03-30T04:11:02.239072Z",
     "shell.execute_reply": "2024-03-30T04:11:02.238387Z",
     "shell.execute_reply.started": "2024-03-30T04:10:11.000974Z"
    },
    "id": "eXNLu_-nIrJI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function prepare_train_features at 0x7fdc6231a5f0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2804a909980843ba92bac7fac79623b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf4c1af5d804a7093c66b24bb4fb8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# datasets.map 处理数据集\n",
    "tokenized_datasets = datasets.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"train\"].column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV",
    "tags": []
   },
   "source": [
    "# 2.微调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 微调参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T04:12:29.487975Z",
     "iopub.status.busy": "2024-03-30T04:12:29.487229Z",
     "iopub.status.idle": "2024-03-30T04:12:42.804373Z",
     "shell.execute_reply": "2024-03-30T04:12:42.803578Z",
     "shell.execute_reply.started": "2024-03-30T04:12:29.487944Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 12:12:32.708323: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-30 12:12:33.150212: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-30 12:12:33.150245: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-30 12:12:33.153198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-30 12:12:33.404714: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-30 12:12:33.406879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-30 12:12:35.238461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at /mnt/workspace/models/distilbert/distilbert-base-uncased/ and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import default_data_collator\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"]=\"llm-dev-qa-fine-tune\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "os.environ[\"WANDB_WATCH\"]=\"true\"\n",
    "\n",
    "#  fuck,v100貌似不支持tf32,所以下面超参数里也注释掉\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(device)\n",
    "print(n_gpu)\n",
    "\n",
    "# 加载要训练的模型\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_distilbert_base_uncased)\n",
    "\n",
    "# Data Collator（数据整理器）\n",
    "data_collator = default_data_collator\n",
    "\n",
    "# 训练超参数（TrainingArguments）\n",
    "args = TrainingArguments(\n",
    "    output_dir=model_distilbert_base_uncased_output_dir,\n",
    "    # 训练过程中进行评估的策略。在这里设置为 \"epoch\"，表示在每个训练轮次结束后进行一次评估。也可以设置为 \"steps\"，表示每训练一定步数后进行评估。\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    # 设置模型的初始学习率\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    # 设置训练的轮次（epochs）数\n",
    "    num_train_epochs=3,\n",
    "    # 设置权重衰减（weight decay）的系数。权重衰减是一种正则化技术，用于避免模型过拟合训练数据。这里设置为 0.01，表示权重衰减的系数为 0.01\n",
    "    weight_decay=0.01,\n",
    "    # tf32=True,\n",
    "    save_total_limit=2, # 控制生成checkpoints文件夹的数量\n",
    "    hub_strategy=\"checkpoint\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    ignore_data_skip=False,\n",
    "    report_to=\"wandb\",\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "# 实例化训练器（Trainer）\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-19T11:47:56.195840Z",
     "iopub.status.busy": "2024-03-19T11:47:56.195364Z",
     "iopub.status.idle": "2024-03-19T13:00:59.455415Z",
     "shell.execute_reply": "2024-03-19T13:00:59.454650Z",
     "shell.execute_reply.started": "2024-03-19T11:47:56.195806Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7267453b69e49c78ef1adc4725ae457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112262000016119, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/workspace/LLM-quickstart/transformers/wandb/run-20240319_194756-tlvv7trm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune/runs/tlvv7trm' target=\"_blank\">golden-pine-2</a></strong> to <a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune' target=\"_blank\">https://wandb.ai/douspeng/llm-dev-qa-fine-tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune/runs/tlvv7trm' target=\"_blank\">https://wandb.ai/douspeng/llm-dev-qa-fine-tune/runs/tlvv7trm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6177' max='6177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6177/6177 1:12:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.362300</td>\n",
       "      <td>1.324668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.194900</td>\n",
       "      <td>1.290374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.093100</td>\n",
       "      <td>1.330887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6177, training_loss=1.3704667433346092, metrics={'train_runtime': 4318.7703, 'train_samples_per_second': 91.522, 'train_steps_per_second': 1.43, 'total_flos': 3.873165421863629e+16, 'train_loss': 1.3704667433346092, 'epoch': 3.0})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练  watch -n 1 nvidia-smi\n",
    "# - SQUAD v2\n",
    "# - model_checkpoint = \"distilbert-base-uncased\"\n",
    "# - batch_size = 64\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T15:02:05.524519Z",
     "iopub.status.busy": "2024-03-19T15:02:05.524049Z",
     "iopub.status.idle": "2024-03-19T15:02:05.918065Z",
     "shell.execute_reply": "2024-03-19T15:02:05.917164Z",
     "shell.execute_reply.started": "2024-03-19T15:02:05.524487Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练完成后，第一时间保存模型权重文件。\n",
    "model_to_save = trainer.save_model(model_distilbert_base_uncased_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3.模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**评估模型输出需要一些额外的处理：将模型的预测映射回上下文的部分。**\n",
    "\n",
    "模型直接输出的是预测答案的`起始位置`和`结束位置`的**logits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 函数定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### prepare_validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T06:31:33.820224Z",
     "iopub.status.busy": "2024-03-30T06:31:33.819626Z",
     "iopub.status.idle": "2024-03-30T06:31:33.826958Z",
     "shell.execute_reply": "2024-03-30T06:31:33.826228Z",
     "shell.execute_reply.started": "2024-03-30T06:31:33.820192Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # 一些问题的左侧有很多空白，这些空白并不有用且会导致上下文截断失败（分词后的问题会占用很多空间）。\n",
    "    # 因此我们移除这些左侧空白\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # 使用截断和可能的填充对我们的示例进行分词，但使用步长保留溢出的令牌。这导致一个长上下文的示例可能产生\n",
    "    # 几个特征，每个特征的上下文都会稍微与前一个特征的上下文重叠。\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # 由于一个示例在上下文很长时可能会产生几个特征，我们需要一个从特征映射到其对应示例的映射。这个键就是为了这个目的。\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # 我们保留产生这个特征的示例ID，并且会存储偏移映射。\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # 获取与该示例对应的序列（以了解哪些是上下文，哪些是问题）。\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # 一个示例可以产生几个文本段，这里是包含该文本段的示例的索引。\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # 将不属于上下文的偏移映射设置为None，以便容易确定一个令牌位置是否属于上下文。\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T06:31:31.113471Z",
     "iopub.status.busy": "2024-03-30T06:31:31.112733Z",
     "iopub.status.idle": "2024-03-30T06:31:31.124429Z",
     "shell.execute_reply": "2024-03-30T06:31:31.123763Z",
     "shell.execute_reply.started": "2024-03-30T06:31:31.113438Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # 构建一个从示例到其对应特征的映射。\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # 我们需要填充的字典。\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # 日志记录。\n",
    "    print(f\"正在后处理 {len(examples)} 个示例的预测，这些预测分散在 {len(features)} 个特征中。\")\n",
    "\n",
    "    # 遍历所有示例！\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # 这些是与当前示例关联的特征的索引。\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None # 仅在squad_v2为True时使用。\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example[\"context\"]\n",
    "        # 遍历与当前示例关联的所有特征。\n",
    "        for feature_index in feature_indices:\n",
    "            # 我们获取模型对这个特征的预测。\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # 这将允许我们将logits中的某些位置映射到原始上下文中的文本跨度。\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # 更新最小空预测。\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # 浏览所有的最佳开始和结束logits，为 `n_best_size` 个最佳选择。\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # 在极少数情况下我们没有一个非空预测，我们创建一个假预测以避免失败。\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        # 选择我们的最终答案：最佳答案或空答案（仅适用于squad_v2）\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T06:52:29.367224Z",
     "iopub.status.busy": "2024-03-30T06:52:29.366721Z",
     "iopub.status.idle": "2024-03-30T06:52:29.404283Z",
     "shell.execute_reply": "2024-03-30T06:52:29.403629Z",
     "shell.execute_reply.started": "2024-03-30T06:52:29.367185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_features = datasets[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"validation\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T06:58:16.685258Z",
     "iopub.status.busy": "2024-03-30T06:58:16.684726Z",
     "iopub.status.idle": "2024-03-30T06:58:16.690092Z",
     "shell.execute_reply": "2024-03-30T06:58:16.689299Z",
     "shell.execute_reply.started": "2024-03-30T06:58:16.685222Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
       "    num_rows: 12134\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T06:58:43.728671Z",
     "iopub.status.busy": "2024-03-30T06:58:43.727841Z",
     "iopub.status.idle": "2024-03-30T06:59:28.472134Z",
     "shell.execute_reply": "2024-03-30T06:59:28.471460Z",
     "shell.execute_reply.started": "2024-03-30T06:58:43.728635Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-30T07:01:26.031747Z",
     "iopub.status.busy": "2024-03-30T07:01:26.031251Z",
     "iopub.status.idle": "2024-03-30T07:01:26.036655Z",
     "shell.execute_reply": "2024-03-30T07:01:26.035924Z",
     "shell.execute_reply.started": "2024-03-30T07:01:26.031715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
       "    num_rows: 12134\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T07:07:21.951336Z",
     "iopub.status.busy": "2024-03-30T07:07:21.950463Z",
     "iopub.status.idle": "2024-03-30T07:07:21.954781Z",
     "shell.execute_reply": "2024-03-30T07:07:21.953799Z",
     "shell.execute_reply.started": "2024-03-30T07:07:21.951302Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trainer会隐藏模型不使用的列（在这里是example_id和offset_mapping，我们需要它们进行后处理），\n",
    "# 所以我们需要将它们重新设置回来\n",
    "# 这也没隐藏啊，蛋疼\n",
    "# validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 打印比较模型输出和标准答案（Ground-truth）是否一致: 现在不一致咋办？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T07:20:04.150774Z",
     "iopub.status.busy": "2024-03-30T07:20:04.150167Z",
     "iopub.status.idle": "2024-03-30T07:20:04.159636Z",
     "shell.execute_reply": "2024-03-30T07:20:04.158895Z",
     "shell.execute_reply.started": "2024-03-30T07:20:04.150740Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def getAnswer(myTrainer):\n",
    "\n",
    "    for batch in myTrainer.get_eval_dataloader():\n",
    "        break\n",
    "    batch = {k: v.to(myTrainer.args.device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        output = myTrainer.model(**batch)\n",
    "    output.keys()\n",
    "    \n",
    "    \n",
    "    n_best_size = 20\n",
    "    max_answer_length = 30\n",
    "    start_logits = output.start_logits[0].cpu().numpy()\n",
    "    end_logits = output.end_logits[0].cpu().numpy()\n",
    "    offset_mapping = validation_features[0][\"offset_mapping\"]\n",
    "\n",
    "    # 第一个特征来自第一个示例。对于更一般的情况，我们需要将example_id匹配到一个示例索引\n",
    "    context = datasets[\"validation\"][0][\"context\"]\n",
    "\n",
    "    # 收集最佳开始/结束逻辑的索引：\n",
    "    start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "    end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "    valid_answers = []\n",
    "    for start_index in start_indexes:\n",
    "        for end_index in end_indexes:\n",
    "            # 不考虑超出范围的答案，原因是索引超出范围或对应于输入ID的部分不在上下文中。\n",
    "            if (\n",
    "                start_index >= len(offset_mapping)\n",
    "                or end_index >= len(offset_mapping)\n",
    "                or offset_mapping[start_index] is None\n",
    "                or offset_mapping[end_index] is None\n",
    "            ):\n",
    "                continue\n",
    "            # 不考虑长度小于0或大于max_answer_length的答案。\n",
    "            if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                continue\n",
    "            if start_index <= end_index: # 我们需要细化这个测试，以检查答案是否在上下文中\n",
    "                start_char = offset_mapping[start_index][0]\n",
    "                end_char = offset_mapping[end_index][1]\n",
    "                valid_answers.append(\n",
    "                    {\n",
    "                        \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                        \"text\": context[start_char: end_char]\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
    "    return valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T07:20:14.208620Z",
     "iopub.status.busy": "2024-03-30T07:20:14.208115Z",
     "iopub.status.idle": "2024-03-30T07:20:14.502281Z",
     "shell.execute_reply": "2024-03-30T07:20:14.501540Z",
     "shell.execute_reply.started": "2024-03-30T07:20:14.208588Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.80216366, 'text': 'in the first half'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_answers= getAnswer(trainer)\n",
    "valid_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T07:13:26.706488Z",
     "iopub.status.busy": "2024-03-30T07:13:26.705994Z",
     "iopub.status.idle": "2024-03-30T07:13:26.712246Z",
     "shell.execute_reply": "2024-03-30T07:13:26.711417Z",
     "shell.execute_reply.started": "2024-03-30T07:13:26.706454Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['France', 'France', 'France', 'France'],\n",
       " 'answer_start': [159, 159, 159, 159]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"validation\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 输出f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T07:02:16.586780Z",
     "iopub.status.busy": "2024-03-30T07:02:16.586278Z",
     "iopub.status.idle": "2024-03-30T07:03:08.844440Z",
     "shell.execute_reply": "2024-03-30T07:03:08.843733Z",
     "shell.execute_reply.started": "2024-03-30T07:02:16.586749Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在后处理 11873 个示例的预测，这些预测分散在 12134 个特征中。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bde68196ea94776868ac353c13aefaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11873 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "examples = datasets[\"validation\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "# 在原始结果上应用后处理问答结果\n",
    "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `datasets.load_metric` 中加载 `SQuAD v2` 的评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-30T07:04:09.295326Z",
     "iopub.status.busy": "2024-03-30T07:04:09.294824Z",
     "iopub.status.idle": "2024-03-30T07:05:56.736793Z",
     "shell.execute_reply": "2024-03-30T07:05:56.736102Z",
     "shell.execute_reply.started": "2024-03-30T07:04:09.295288Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/metrics/squad_v2/2331e6999295d76b19484c2e2bec2c45e44361978b4622449ee990f0bb47ba5e (last modified on Wed Mar 20 09:57:23 2024) since it couldn't be found locally at squad_v2, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact': 0.8927819422218479,\n",
       " 'f1': 4.671281408230188,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 0.20242914979757085,\n",
       " 'HasAns_f1': 7.770263859635135,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 1.5811606391925987,\n",
       " 'NoAns_f1': 1.5811606391925987,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 50.07159100480081,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 50.08135341454637,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\",trust_remote_code=True)\n",
    "\n",
    "if squad_v2:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "else:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6.Homework：加载本地保存的模型，进行评估和再训练更高的 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-20T06:01:05.171767Z",
     "iopub.status.busy": "2024-03-20T06:01:05.171267Z",
     "iopub.status.idle": "2024-03-20T06:01:05.281605Z",
     "shell.execute_reply": "2024-03-20T06:01:05.280859Z",
     "shell.execute_reply.started": "2024-03-20T06:01:05.171734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 再训练,使用删词训练完的模型\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(model_distilbert_base_uncased_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-20T06:01:09.776669Z",
     "iopub.status.busy": "2024-03-20T06:01:09.776155Z",
     "iopub.status.idle": "2024-03-20T06:01:09.846175Z",
     "shell.execute_reply": "2024-03-20T06:01:09.845510Z",
     "shell.execute_reply.started": "2024-03-20T06:01:09.776633Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# 实例化训练器（Trainer）\n",
    "trained_trainer = Trainer(\n",
    "    trained_model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-20T02:37:16.346926Z",
     "iopub.status.busy": "2024-03-20T02:37:16.346430Z",
     "iopub.status.idle": "2024-03-20T02:37:16.350504Z",
     "shell.execute_reply": "2024-03-20T02:37:16.349811Z",
     "shell.execute_reply.started": "2024-03-20T02:37:16.346892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 清理GPU\n",
    "# del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T06:01:22.660775Z",
     "iopub.status.busy": "2024-03-20T06:01:22.660293Z",
     "iopub.status.idle": "2024-03-20T07:13:10.496278Z",
     "shell.execute_reply": "2024-03-20T07:13:10.495446Z",
     "shell.execute_reply.started": "2024-03-20T06:01:22.660741Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdouspeng\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a464f186b64efe92b8fa98de47d2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112331244415448, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/workspace/LLM-quickstart/transformers/wandb/run-20240320_140125-68615m65</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune/runs/68615m65' target=\"_blank\">comfy-hill-3</a></strong> to <a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune' target=\"_blank\">https://wandb.ai/douspeng/llm-dev-qa-fine-tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/douspeng/llm-dev-qa-fine-tune/runs/68615m65' target=\"_blank\">https://wandb.ai/douspeng/llm-dev-qa-fine-tune/runs/68615m65</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6177' max='6177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6177/6177 1:11:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>1.449725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>1.466305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>1.549576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (TransientError), entering retry loop.\n",
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6177, training_loss=0.8256300647841199, metrics={'train_runtime': 4302.6013, 'train_samples_per_second': 91.866, 'train_steps_per_second': 1.436, 'total_flos': 3.873165421863629e+16, 'train_loss': 0.8256300647841199, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练  watch -n 1 nvidia-smi\n",
    "# - SQUAD v2\n",
    "# - model_checkpoint = \"distilbert-base-uncased-fine-tune-squad\"\n",
    "# - batch_size = 64\n",
    "trained_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T07:47:28.434831Z",
     "iopub.status.busy": "2024-03-20T07:47:28.434331Z",
     "iopub.status.idle": "2024-03-20T07:47:29.022603Z",
     "shell.execute_reply": "2024-03-20T07:47:29.021688Z",
     "shell.execute_reply.started": "2024-03-20T07:47:28.434798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练完成后，第一时间保存模型权重文件。\n",
    "model_distilbert_base_uncased_fine_tune_2_output_dir = f\"{model_dir}/distilbert/distilbert-base-uncased-fine-tune-squad-2\"\n",
    "model2_to_save = trained_trainer.save_model(model_distilbert_base_uncased_fine_tune_2_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.再次评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T13:06:35.654836Z",
     "iopub.status.busy": "2024-03-20T13:06:35.654353Z",
     "iopub.status.idle": "2024-03-20T13:06:35.667482Z",
     "shell.execute_reply": "2024-03-20T13:06:35.666627Z",
     "shell.execute_reply.started": "2024-03-20T13:06:35.654805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_features = datasets[\"validation\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"validation\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T13:06:40.915805Z",
     "iopub.status.busy": "2024-03-20T13:06:40.915326Z",
     "iopub.status.idle": "2024-03-20T13:07:26.394973Z",
     "shell.execute_reply": "2024-03-20T13:07:26.394183Z",
     "shell.execute_reply.started": "2024-03-20T13:06:40.915774Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_predictions = trained_trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T13:07:43.595151Z",
     "iopub.status.busy": "2024-03-20T13:07:43.594654Z",
     "iopub.status.idle": "2024-03-20T13:07:43.601291Z",
     "shell.execute_reply": "2024-03-20T13:07:43.600335Z",
     "shell.execute_reply.started": "2024-03-20T13:07:43.595118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-20T13:07:45.900457Z",
     "iopub.status.busy": "2024-03-20T13:07:45.899966Z",
     "iopub.status.idle": "2024-03-20T13:08:28.279561Z",
     "shell.execute_reply": "2024-03-20T13:08:28.278403Z",
     "shell.execute_reply.started": "2024-03-20T13:07:45.900425Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在后处理 11873 个示例的预测，这些预测分散在 12134 个特征中。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbdb55419de456d896b335d9887f239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11873 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T12:42:48.514842Z",
     "iopub.status.busy": "2024-03-20T12:42:48.514157Z",
     "iopub.status.idle": "2024-03-20T12:42:54.907245Z",
     "shell.execute_reply": "2024-03-20T12:42:54.906405Z",
     "shell.execute_reply.started": "2024-03-20T12:42:48.514810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10057/309493902.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\",trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\",trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T13:11:23.386038Z",
     "iopub.status.busy": "2024-03-20T13:11:23.385534Z",
     "iopub.status.idle": "2024-03-20T13:11:25.903802Z",
     "shell.execute_reply": "2024-03-20T13:11:25.902691Z",
     "shell.execute_reply.started": "2024-03-20T13:11:23.385998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 61.91358544596985,\n",
       " 'f1': 65.4797797475251,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 66.19433198380567,\n",
       " 'HasAns_f1': 73.33694752738931,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 57.64507989907485,\n",
       " 'NoAns_f1': 57.64507989907485,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 61.938852859428955,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 65.49662468983149,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if squad_v2:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "else:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Question Answering on SQUAD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
